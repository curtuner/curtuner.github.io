#+TITLE: 功能分析总结
#+DATE: 2018-05-14
#+LAYOUT: post
#+TAGS: summary
#+CATEGORIES: summary

* 前言
  本文主要想讲一下OCR功能以及历史检索功能涉及到的技术，让大家有一个大体的了解，多数堡垒机对于这部分的都没有过于深入。另外就是近期对架构的一点思考。
  当前文字识别面临的困难：
  1) 开源的文字识别库，中文识别率都不是很让人满意
  2) 完整的问题识别
  
  对于RDP文字识别的稍微能取巧的地方：
  1) RDP协议本身支持传输字模（Glyph）数据，字模的识别率非常高，一般开源的OCR库就能提供不错的效果。也就是有部分数据可以精确识别。
  2) 多数文字都比较规则，不用处理手写的字体或者不同角度的处理，预处理相对简单。
* OCR功能
  OCR是一个多学科交叉领域，涉及到计算机视觉（图像处理）、模式识别、机器学习和神经网络等方面知识。OCR主要分成了两个部分：
  1) 文字提取
  2) 文字识别
     
  这两部分分别属于不同的领域，前者是图像处理，涉及到图像分割的知识，后者是文字识别。文字提取相比文字识别要麻烦得多。文字识别只要关注提升对单个文字的识别率就可以了。
** 文字提取
   文字提取相比文字识别要麻烦得多，
   对于远程桌面的字体数据，几个特点是：
   1) 字体基本是印刷字体
   2) RDP协议直接传输部分文字的字模（Glyph）
   实际上RDP已经帮我们提取了一部分文字，只要在guacd中截取这一部分数据就可以用于识别了，除此之外还有一部分文字由于不是由Window进行渲染所以只能以图片的形式传输，这里的文字提取主要就是指的这种情况。多数堡垒机的OCR功能都没有处理这一部分数据。也就是说并没有进行文字提取。
** 文字识别
*** 当前文字识别软件面临的问题
   目前大多数都是文字识别，都是识别的RDP协议中传输的字模（Glyph），对于没能称为字模的程序无法识别。至于文字识别会呈现为字模（Glyph），一般取决于软件的实现。比如，打开包含文字的图片，就不会传输字模，这就造成了一个问题，如果不独立分析字模，一般字模是相对重要的数据，可以输出字模的程序包括：
   - Windows各种自带的工具软件（类似cmd，powershell）
   总之借助字模识别可以完成大部分RDP指令的审计。但是模糊识别就比较可惜了。
*** 字模和图像文字识别
    RDP对此其实区分得比较好了，所以可以通过预处理来完成这两类字体的区分。
*** Google Tesseract OCR引擎
    Tesseract的OCR引擎最早于1985年由HP实验室开始研发，1995年该引擎已经成为OCR业内最准确的三款识别引擎之一。Tesseract目前已作为开源项目发布在Google Project。
    目前Tesseract-ocr提供了Python API和C API。直接使用Tesseract-ocr的话两者的接口斗不难使用，
*** Tesseract-OCR准确率
    目前对于Tesseract-ocr的研究还卡在提升准确率上，中文的识别率基本没什么问题，这个得益于tesseract-ocr提供的样本库原本就是印刷字体，正好和远程桌面的场景类似。问题反而是对于默认情况下对于汉英混合的识别率问题。远程桌面中英文有些场景还是比较多的。
   对于RDP传输的字体的问题反而是
*** Tesseract的训练
* 历史记录的存储和索引
  经过了OCR处理之后，接下来要处理的数据就都是文本数据。这些文本数据比较特别，没有固定结构。所以检索也是基于关键词来检索，如果不去分词，很多软件会以字为单位来检索，这个其实没有多大意义，一般都搜索引擎都不会这么做。尤其是数据量一大，这么做就几乎没有价值。
** 数据存储
   Gucamole和Jumpserver都有自己的历史记录存储方式，Guacmole是是个文本文件，Jumpserver倾向于存入数据库。暂时看来，在不涉及全文检索的情况下，区别没那么大。当然关系数据库其实并不是很适合处理这种问题。
*** Guacamole原始存储文件格式
    文件主要存储两种信息，提取出的文字和时间，方便起见由于Guacmole协议的历史文件是每隔200ms打一个时间戳，比较齐整。文件方便检索。设计的思路可以很简单。最简单的做法是对照Guacamole历史文件在每个时间戳之间记录文件的文件的格式。
    以一般的架构来说，存储文件格式属于比较底层的东西，但是一旦涉及到检索的。那么和文件格式就比较靠近了。
    目前就是先借鉴其他软件来完成原型。
    目前像Guacmole是直接使用
*** 添加通过RDP传输的字符
    原始的Guacamole历史文件是按照时间顺序来记录传输的数据，按照同样的逻辑把字符信息插入到Guacamole历史文件是比较合理的做法。只要在前端增加对字符信息的处理即可。至于没有通过RDP传输的字符（比如浏览器中的文字，PDF之类的），这一类字符比较杂乱，比如很可能一段内容被一个窗口挡住了一大半，
** 历史记录检索
   要针对特定内容进行检索的时候，不可能每次都遍历一次所有的文件，a就像source insight一样，一般都是先根据所有文件建立索引，之后才能高效检索。索引文件一般是特定的数据结构的持久化格式。不依赖于特定数据结构。
   检索功能根据范围主要分成三种：
   1) 单个历史记录的检索
   2) 小数量级的多个历史记录的检索
   3) 大数量级的多个历史记录的检索

   单个历史记录的检索是最简单的，由于数据量不大，可以采用直接放到内存中遍历一遍的方式，推荐直接在前端完成。如果是查询某个用户在某段时间内的操作历史这一类的小数量级的检索，也可以直接由前端在获取所有数据之后遍历检索，开销也可以接受。最大的难点还是在于大数量级的多个历史记录的检索，这个涉及 *全文检索* 领域。
  另外，由于数据量的差异，字符协议遇到大规模检索问题的会比较晚，并不是不会遇到。
*** 全文索引技术
    随着数据量的增长，传统的关系数据库很难快速定位所需的数据。为了处理这个问题，需要使用全文检索技术。全文检索技术可以根据关键字和检索条件从各种文本快速搜索匹配的相关文本信息[fn:1:其实就是百度这类搜索引擎使用的技术]。目前主流的关系数据库斗支持全文检索技术，当然完成度各不相同，Postgresql回比MySQL好一些，但是涉及中文的检索还是需要特别的处理。目前来说，关系数据库的全文检索并不适合比较复杂的需求。除了关系数据库之外，提供全文检索的工具还包括Apache Lucene框架。
*** 中文分词
    中文分词(Chinese Word Segmentation) 指的是将一个汉字序列切分成一个一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。英文中单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符，虽然英文也同样存在短语的划分问题，不过在词这一层上，中文比之英文要复杂得多、困难得多。由于基础软件大多是是英文世界的软件，所以对中文的全文检索都有支持上的不足，第一个要克服的困难就是分词问题。分词也是一个比较专业的领域，能用的主要就是：
    1) 结巴中文分词
    2) 中科院分词系统
    
    当然分词的准确率还是不可能做到百分百，毕竟自然语言的语义分析其实目前依旧是业界难点。分词暂时还是基于统计机器学习方法。也就是说无论是文字识别还是检索效果都比较有限。另外其实字符协议也可能涉及到中文的问题，不过考虑到中文数量极小，也不用太操心。
*** Apache Lucene
    首先这是一个完成度很高的软件，在全文检索的领域也是比较出名的软件。当然它是一个框架，不算一个应用软件，要测试其效果可以尝试一下基于它的两个比较出名的软件是：
    1) DocFetcher
    2) Apache solr
    3) Nutch
    
    通过简单定制和优化可以满足上亿级别的检索，同时也支持分布式。之所以需要分布式，主要是全文检索本身是一个开销极大的功能，使用关系数据库的全文检索功能的时候也要小心对数据库性能造成影响。
    由于Lucene是使用Java编写的软件，所以基于Lucene的项目大多也是Java项目。当然，Python可以通过使用PyLucene来使用Lucene。
*** 零散
   全文检索技术
   目前支持全文检索功能还是基于文本文件来
   桌面的检索本质上是中英的全文检索
   关系数据库
   另一方面MySQL和PostgreSQL也提供了全文检索功能，对于审计来说这个东西是必要的，可以加快检索的速度，也就是说除了图形这一块，字符也需要了解一下全文检索的使用。当然性能上不好说。而且对于中文的支持也是一个问题。
     
* 软件架构问题
** MVC[fn:5:这里的MVC指的是改进后的MVC，而不是原始的MVC]、MVP、MVVM的联系
   三者其实都是为了UI而设计的东西，原本是为了处理桌面软件的设计问题，后来被引入和Web。但是基本的思想都差不多，很容易发现，它们的名称中都有MV这两个字母，也就是：
   - M（模型）：业务逻辑
   - V（视图）：图形界面
   
   说白了，几种架构的目标都是把业务逻辑从界面设计中分离开来，原因是大家发现关于图形界面的需求变动速度远比业务逻辑变动得快。按照《Unix编程艺术》中的概念，其实这个做法遵守了策略和机制分离的原则。遵守这个原则的除了涉及UI的软件之外，还包括涉及数据库操作的软件。也就是对于说最终需要操作数据库的程序，最好也参照MVC架构一样把业务逻辑和实际的数据库操作拆分成独立的两部分。
   MV的分离其实已经是这些架构的目标了，极端理想的情况下当然是希望两个模块能直接组合起来使用，也就是说如果可以，没人想在MV两个模块中再加入一个模块。但做不到，不管是开发上的问题还是性能上的问题都让人们不得不在原来两个模块的基础上再加入一个模块来作为“粘合剂”，就是这个“粘合剂”造成了几种架构的区别。至于“粘合剂”的区别这里就不讲了，容易涉及到一些麻烦的概念，知道这些架构的目标即可。
** 前后端分离
   三者都是设计架构，理解需要一些时间，这里不多解释其具体概念。讲一下涉及到的麻烦。目前就我们的技术选型上就涉及到了MVC和MVVM，其中Django用的是是MVC架构，vue.js用的是MVVM架构。虽说还有PHP这一块比较胶着的部分，但是个人最终还是会倾向于按照前后端分离的方式来开发。也就是说在最终可能前后端各自都会使用一个架构。这里看一下前后端分离，前后端架构的关系图：
   [[./功能分析总结/client-side-mvc.jpg]]

   可以看到此时前端的架构只负责页面展示，所以它是后端MVC框架的View层。之后如果我们是基于JumpServer来开发，大概就需要花时间来学习Django框架，基本上Django关于View层的东西都不值得花太多时间了。
** REST
   对于REST的理解其实从软件架构的层面来理解会好很多。就个人近期学习软件工程的结果上来看，一般的软件架构可以大体分成三层：
   - 业务逻辑层(策略层)
   - 胶合层
   - 机制层（包括框架、驱动、数据库等）

   其中胶合层的主要任务是把适合业务逻辑处理的形式转化成适合底层处理的形式，如Web、数据库、GUI库等。对于堡垒机来说Web框架、数据库选型以及其他的技术选型其实在软件架构中都属于底层。现代软件工程的经验认为，这些都是容易变动的部分。所以会不辞辛苦的把业务逻辑和特定技术区分开。对于框架的使用如今也越来越保守，目前推崇在业务逻辑部分尽量少使用框架，只在最底层使用框架。同时避免让框架处理复杂的逻辑。这个其实没那么简单，因为框架本身就有入侵代码的倾向。想知道代码是否将业务逻辑和框架区分开来其实很简单，只要分析一下如果直接换一个框架，对于业务逻辑代码需要修改多少就可以了，理想情况也业务逻辑的代码应该几乎不会改动。类似的，数据库情况也是一样的，能在需求改变的时候简单地切换数据库类型也是比较重要的，比如就现在来说为了方便开发，直接选用了MySQL的处理数据，但是一旦以后需要处理分布式存储的问题或者加一个类似MongoDB之类的文档数据库的时候，可能就会觉得还不如一开始就选用PostgreSQL这种功能更全面的数据库。

   提到业务逻辑和机制的分离，使用过Web框架一般能发现，框架本身提供了机制来帮助用户把两者分离（例如MVC框架中，M（模型）属于业务逻辑，controler（控制器）属于胶合层、V（视图）属于机制层），代价就是你再难以让自己的代码和框架分离。所以怎么用框架其实是很麻烦的问题。
   
   虽说REST是一种架构风格，但是用开发堡垒机的眼光来看其实就是一种工具，它应该属于胶合层而不是整个架构。实现RESTful API的目标就是把业务层的比较抽象的形式转化成适合Web处理的形式。至于RESTful经常被放到和数据库一块讨论就显得没必要了，虽然REST常常用于处理从数据库获取数据的应用，但是两者相关性其实没多大。

   这里需要先理解的概念是什么是工具（也就是框架和驱动层）：
   - Web框架
   - MVC设计规范
   
   本质上REST架构风格属于胶合层的内容，胶合层的主要任务是
* 总结
  首先，问题是是否满足于只分析RDP中直接传输的字模数据？如果是，那么以上很多提到的技术其实都用不上，很多软件也可以转而使用弱化的替代品。多数堡垒机其实都没有更进一步。如果只是达到目前多数堡垒机的程度（像行云）的话，其实简单使用一下tesseract-ocr并且定制一下Lucene（或者存数据库）即可。如果要进行完整的文字内容分析，那么涉及的东西就比较繁杂了，包括：
  1) 图像处理
  2) 文字识别
  3) 全文检索
  4) 中文分词
  5) 机器学习和神经网络等方面知识

  虽然可能不需要了解得过于深入。

* 参考
  - [[https://baike.baidu.com/item/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/1140318?fr=aladdin][全文索引介绍]]
  - 《开发数据密集型应用》
  - [[http://2014.jsconf.cn/slides/herman-taobaoweb/#/55][淘宝前后端分离实践]]
  - Lucene中文分词在电子档案全文检索中的应用研究
  - [[https://zh.wikipedia.org/wiki/%E5%85%89%E5%AD%A6%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB][光学字符识别 wiki]]
* 零散
** 功能选择
   以上只是可能涉及到的技术点的简单介绍，实际没有必要一步到位，具体会使用多少要看实际的需求。目前多数堡垒机只是基本的对RDP传输的文字进行简单识别，并提供了单个历史记录的检索功能而已。
   #+BEGIN_SRC plantuml :file
   
   #+END_SRC
** 具体嵌入Guacamole的方法
   Guacamole使用Guacamole协议来记录相应的历史，关系数据库可能不是很合适。涉及到文字的部分。RDP的glyph完全可以作为嵌入的文字来使用。这部分文字是最简单的，所以可以直接增加Guacamole的文字处理部分。然后直接在前端显示。那么这一部分就可以完成了。之后就是不能使用glyph传输的问题，这是最大的难点，一般情况下只能根据需要添加到历史文件中。之后逐渐完成这种处理。按照这种逻辑，VNC之后也可以逐步添加。测试起来也算方便。也可以逐步增加完成。
   下一个问题就是如何完成检索的支持，至于根据已有的元数据检索什么的到是好实现。根据相应单纯文字进行识别就比较麻烦了，这个需要对完整的数据进行分析，最简单的是直接遍历所有识别出来的文字，当时这样随着数据量的增加越发不显示。所以大体上需要某种方便检索的数据结构，比如前缀树什么的。高效的检索方式本身是一个大的主题。
** 关系数据库和文档数据库
   近期可能涉及，MongoDB和Mysql的区别问题，其实这个是两个数据模型的对比。目前主流的数据模型主要有三个：
   1) 关系模型
   2) 文档模型
   3) 图模型
   
   图模型目前只看到净云涉及到了，支持关系关系模型主要就是现在主流的数据库：MySQL、PostgreSQL和Oracle。
   特别需要注意的是传统的关系数据库目前正在和文档数据库融合的过程，PostgreSQL对文档模型的支持已经很不错了，MySQL则是刚刚起步。
** 问题
   1) 要不要处理RDP协议不传输的那一部分文字，以及VNC的那一部分文字
   2) 要不要处理特定应用的涉及的字体
   3) 文字提取
   4) 要不要文字检索
