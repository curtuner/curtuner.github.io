#+TITLE: 功能分析总结
#+DATE: 2018-05-14
#+LAYOUT: post
#+TAGS: summary
#+CATEGORIES: summary

* 前言
  本文主要想讲一下OCR功能以及历史检索功能涉及到的技术，让大家有一个大体的了解。另外就是近期对架构的一点思考。
  当前文字识别面临的困难：
  1) 开源的文字识别库，中文识别率都不是很让人满意
  2) 完整的问题识别
  
  对于RDP文字识别的稍微能取巧的地方：
  1) RDP协议本身支持传输字模（Glyph）数据，字模的识别率非常高，一般开源的OCR库就能提供不错的效果。也就是有部分数据可以精确识别。
  2) 多数文字都比较规则，不用处理手写的字体或者不同角度的处理，预处理相对简单。

  对于实际需求来说，文字识别只是其中一个部分。提取出文字之后要做的就是检索了。检索功能根据范围主要分成三种：
  1) 单个历史记录的检索
  2) 小数量级的多个历史记录的检索
  3) 大数量级的多个历史记录的检索
  
  单个历史记录的检索是最简单的，由于数据量不大，可以采用直接放到内存中遍历一遍的方式，推荐直接在前端完成。小数量级的多个历史记录的检索具体的情况可能是查询某个用户某段时间内涉及的操作。如果只有十几二十份这个数量级的话也可以直接有前端获取所有数据之后检索，开销也可以接受。最大的难点还是在于大数量级的多个历史记录的检索，这个涉及全文检索领域。
  另外，由于数据量的差异，字符协议中主要是遇到大规模检索问题的时比较晚，并不是不会遇到。
* OCR功能
  OCR是一个多学科交叉领域，涉及到计算机视觉（图像处理）、模式识别、机器学习和神经网络等方面知识。
** 文字提取
   实际上RDP已经帮我们提取了一部分文字，只要在guacd中截取这一部分数据就可以用于识别了，除此之外还有一部分文字由于不是由Window进行渲染所以只能以图片的形式传输，这里的文字提取主要就是指的这种情况。多数堡垒机的OCR功能都没有处理这一部分数据。也就是说并没有进行文字提取。
** 文字识别
*** Google Tesseract OCR引擎
    Tesseract的OCR引擎最早于1985年由HP实验室开始研发，1995年该引擎已经成为OCR业内最准确的三款识别引擎之一。Tesseract目前已作为开源项目发布在Google Project。
    目前Tesseract-ocr提供了Python API和C API。直接使用Tesseract-ocr的话两者的接口斗不难使用，
*** Tesseract-OCR准确率
    目前对于Tesseract-ocr的研究还卡在提升准确率上，中文的识别率基本没什么问题，这个得益于tesseract-ocr提供的样本库原本就是印刷字体，正好和远程桌面的场景类似。问题反而是对于默认情况下对于汉英混合的识别率问题。远程桌面中英文有些场景还是比较多的。
   对于RDP传输的字体的问题反而是
*** Tesseract的训练
* 历史记录的存储和索引
  经过了OCR处理之后，接下来要处理的数据就都是文本数据了
** 数据存储
   
** 全文检索
   除了对于远程桌面历史文件的检索，其他的文本文件也有一定。特色文件
* 功能选择
  以上只是可能涉及到的技术点的简单介绍，实际没有必要一步到位，具体会使用多少要看实际的需求。目前多数堡垒机只是基本的对RDP传输的文字进行简单识别，并提供了单个历史记录的检索功能而已。
  #+BEGIN_SRC plantuml :file
  
  #+END_SRC
* 基本概念
  OCR主要分成了两个部分：
  1) 文字提取
  2) 文字识别
  
  这两部分分别属于不同的领域，前者是图像处理，后者是文字识别。
* 文字提取
  对于远程桌面数据，几个特点是：
  1) 字体基本是印刷字体
  2) RDP协议能提取文字
* 当前文字识别软件面临的问题
  目前大多数都是文字识别，都是识别的RDP协议中传输的字模（Glyph），对于没能称为字模的程序无法识别。至于文字识别会呈现为字模（Glyph），一般取决于软件的实现。比如，打开包含文字的图片，就不会传输字模，这就造成了一个问题，如果不独立分析字模，一般字模是相对重要的数据，可以输出字模的程序包括：
  - Windows各种自带的工具软件（类似cmd，powershell）
  总之借助字模识别可以完成大部分RDP指令的审计。但是模糊识别就比较可惜了。
** 字模和图像文字识别
   RDP对此其实区分得比较好了，所以可以通过预处理来完成这两类字体的区分。
* 文字识别工具
  效果比较好文字识别工具本身属于比较容易盈利，所以大多不会开源。文字识别涉及的工具大体分成两种：
  1) 预处理工具 
  2) 识别工具
** Tesseract-ocr
   Tesseract-ocr提供了C语言和Python的接口，使用Python接口自然是最方便的。
* Guacamole原始存储文件格式
  文件主要存储两种信息，提取出的文字和时间，方便起见由于Guacmole协议的历史文件是每隔200ms打一个时间戳，比较齐整。文件方便检索。设计的思路可以很简单。最简单的做法是对照Guacamole历史文件在每个时间戳之间记录文件的文件的格式。
  以一般的架构来说，存储文件格式属于比较底层的东西，但是一旦涉及到检索的。那么和文件格式就比较靠近了。
  目前就是先借鉴其他软件来完成原型。
  目前像Guacmole是直接使用
  
* 具体嵌入Guacamole的方法
  Guacamole使用Guacamole协议来记录相应的历史，关系数据库可能不是很合适。涉及到文字的部分。RDP的glyph完全可以作为嵌入的文字来使用。这部分文字是最简单的，所以可以直接增加Guacamole的文字处理部分。然后直接在前端显示。那么这一部分就可以完成了。之后就是不能使用glyph传输的问题，这是最大的难点，一般情况下只能根据需要添加到历史文件中。之后逐渐完成这种处理。按照这种逻辑，VNC之后也可以逐步添加。测试起来也算方便。也可以逐步增加完成。
  下一个问题就是如何完成检索的支持，至于根据已有的元数据检索什么的到是好实现。根据相应单纯文字进行识别就比较麻烦了，这个需要对完整的数据进行分析，最简单的是直接遍历所有识别出来的文字，当时这样随着数据量的增加越发不显示。所以大体上需要某种方便检索的数据结构，比如前缀树什么的。高效的检索方式本身是一个大的主题。
* 文本检索技术
  要针对特定内容进行检索的时候，不可能每次都遍历一次所有的文件，就像source insight一样，一般都是先根据所有文件建立索引，之后才能高效检索。索引文件一般是特定的数据结构的持久化格式。不依赖于特定数据结构。文本处理就可以了。
* Tesseract-ocr的开销
  
* 本地文本检索的问题
  相对于全文检索，其实有点类似的
* 全文索引技术
** 简单介绍
  随着数据量的增长，传统的关系数据库很难快速定位所需的数据。为了处理这个问题，需要使用全文检索技术。全文检索技术可以根据关键字和检索条件从各种文本快速搜索匹配的相关文本信息[fn:1:其实就是百度这类搜索引擎使用的技术]。目前主流的关系数据库斗支持全文检索技术，当然完成度各不相同，Postgresql回比MySQL好一些，但是涉及中文的检索还是需要特别的处理。目前来说，关系数据库的全文检索并不适合比较复杂的需求。除了关系数据库之外，提供全文检索的工具还包括Apache Lucene框架。
** 中文分词
   中文分词(Chinese Word Segmentation) 指的是将一个汉字序列切分成一个一个单独的词。分词就是将连续的字序列按照一定的规范重新组合成词序列的过程。英文中单词之间是以空格作为自然分界符的，而中文只是字、句和段能通过明显的分界符来简单划界，唯独词没有一个形式上的分界符，虽然英文也同样存在短语的划分问题，不过在词这一层上，中文比之英文要复杂得多、困难得多。由于基础软件大多是是英文世界的软件，所以对中文的全文检索都有支持上的不足，第一个要克服的困难就是分词问题。分词也是一个比较专业的领域，能用的主要就是：
   1) 结巴中文分词
   2) 中科院分词系统
   
   当然分词的准确率还是不可能做到百分百，毕竟自然语言的语义分析其实目前依旧是业界难点。分词暂时还是基于统计机器学习方法。也就是说无论是文字识别还是检索效果都比较有限。
** Apache Lucene
   首先这是一个完成度很高的软件，在全文检索的领域也是比较出名的软件。当然它是一个框架，不算一个应用软件，要测试其效果可以尝试一下基于它的两个比较出名的软件是：
   1) DocFetcher
   2) Apache solr
   3) Nutch
   
   通过简单定制和优化可以满足上亿级别的检索，同时也支持分布式。之所以需要分布式，主要是全文检索本身是一个开销极大的功能，使用关系数据库的全文检索功能的时候也要小心对数据库性能造成影响。
   由于Lucene是使用Java编写的软件，所以基于Lucene的项目大多也是Java项目。当然，Python可以通过使用PyLucene来使用Lucene。
** 零散
  全文检索技术
  目前支持全文检索功能还是基于文本文件来
  桌面的检索本质上是中英的全文检索
  关系数据库
  目前比较好用的全文检索库叫Lucene，使用Java实现，提供了Python API，叫PyLucene。
  另一方面MySQL和PostgreSQL也提供了全文检索功能，对于审计来说这个东西是必要的，可以加快检索的速度，也就是说除了图形这一块，字符也需要了解一下全文检索的使用。当然性能上不好说。而且对于中文的支持也是一个问题。
* 中文的困难
  远程桌面协议相比字符协议一大问题是，中文的处理的在应用中的分量要大得多。当然，字符协议其实也会涉及处理中文的问题，但是目前并不是普及，即使不对中文做额外处理，也可以接受。
* 关系数据库和文档数据库
  近期可能涉及，MongoDB和Mysql的区别问题，其实这个是两个数据模型的对比。目前主流的数据模型主要有三个：
  1) 关系模型
  2) 文档模型
  3) 图模型
  
  图模型目前只看到净云涉及到了，支持关系关系模型主要就是现在主流的数据库：MySQL、PostgreSQL和Oracle。
  特别需要注意的是传统的关系数据库目前正在和文档数据库融合的过程，PostgreSQL对文档模型的支持已经很不错了，MySQL则是刚刚起步。
* REST
  对于REST的理解其实从软件架构的层面来理解会好很多。就个人近期学习软件工程的结果上来看，一般的软件架构可以大体分成三层：
  - 业务逻辑层(策略层)
  - 胶合层
  - 机制层（包括框架、驱动、数据库等）

  其中胶合层的主要任务是把适合业务逻辑处理的形式转化成适合底层处理的形式，如Web、数据库、GUI库等。对于堡垒机来说Web框架、数据库选型以及其他的技术选型其实在软件架构中都属于底层。现代软件工程的经验认为，这些都是容易变动的部分。所以会不辞辛苦的把业务逻辑和特定技术区分开。对于框架的使用如今也越来越保守，目前推崇在业务逻辑部分尽量少使用框架，只在最底层使用框架。同时避免让框架处理复杂的逻辑。这个其实没那么简单，因为框架本身就有入侵代码的倾向。想知道代码是否将业务逻辑和框架区分开来其实很简单，只要分析一下如果直接换一个框架，对于业务逻辑代码需要修改多少就可以了，理想情况也业务逻辑的代码应该几乎不会改动。类似的，数据库情况也是一样的，能在需求改变的时候简单地切换数据库类型也是比较重要的，比如就现在来说为了方便开发，直接选用了MySQL的处理数据，但是一旦以后需要处理分布式存储的问题或者加一个类似MongoDB之类的文档数据库的时候，可能就会觉得还不如一开始就选用PostgreSQL这种功能更全面的数据库。

  提到业务逻辑和机制的分离，使用过Web框架一般能发现，框架本身提供了机制来帮助用户把两者分离（例如MVC框架中，M（模型）属于业务逻辑，controler（控制器）属于胶合层、V（视图）属于机制层），代价就是你再难以让自己的代码和框架分离。所以怎么用框架其实是很麻烦的问题。
  
  虽说REST是一种架构风格，但是用开发堡垒机的眼光来看其实就是一种工具，它应该属于胶合层而不是整个架构。实现RESTful API的目标就是把业务层的比较抽象的形式转化成适合Web处理的形式。至于RESTful经常被放到和数据库一块讨论就显得没必要了，虽然REST常常用于处理从数据库获取数据的应用，但是两者相关性其实没多大。

  这里需要先理解的概念是什么是工具（也就是框架和驱动层）：
  - Web框架
  - MVC设计规范
  
  本质上REST架构风格属于胶合层的内容，胶合层的主要任务是
* 关于依赖注入
** 工具使用上的问题
* 软件架构问题
** MVC[fn:5:这里的MVC指的是改进后的MVC，而不是原始的MVC]、MVP、MVVM的联系
   三者其实都是为了UI而设计的东西，原本是为了处理桌面软件的设计问题，后来被引入和Web。但是基本的思想都差不多，很容易发现，它们的名称中都有MV这两个字母，也就是：
   - M（模型）：业务逻辑
   - V（视图）：图形界面
   
   说白了，几种架构的目标都是把业务逻辑从界面设计中分离开来，原因是大家发现关于图形界面的需求变动速度远比业务逻辑变动得快。按照《Unix编程艺术》中的概念，其实这个做法遵守了策略和机制分离的原则。遵守这个原则的除了涉及UI的软件之外，还包括涉及数据库操作的软件。也就是对于说最终需要操作数据库的程序，最好也参照MVC架构一样把业务逻辑和实际的数据库操作拆分成独立的两部分。
   MV的分离其实已经是这些架构的目标了，极端理想的情况下当然是希望两个模块能直接组合起来使用，也就是说如果可以，没人想在MV两个模块中再加入一个模块。但做不到，不管是开发上的问题还是性能上的问题都让人们不得不在原来两个模块的基础上再加入一个模块来作为“粘合剂”，就是这个“粘合剂”造成了几种架构的区别。至于“粘合剂”的区别这里就不讲了，容易涉及到一些麻烦的概念，知道这些架构的目标即可。
** 前后端分离
   三者都是设计架构，理解需要一些时间，这里不多解释其具体概念。讲一下涉及到的麻烦。目前就我们的技术选型上就涉及到了MVC和MVVM，其中Django用的是是MVC架构，vue.js用的是MVVM架构。虽说还有PHP这一块比较胶着的部分，但是个人最终还是会倾向于按照前后端分离的方式来开发。也就是说在最终可能前后端各自都会使用一个架构。这里看一下前后端分离，前后端架构的关系图：
   [[./功能分析总结/client-side-mvc.jpg]]

   可以看到此时前端的架构只负责页面展示，所以它是后端MVC框架的View层。之后如果我们是基于JumpServer来开发，大概就需要花时间来学习Django框架，基本上Django关于View层的东西都不值得花太多时间了。

* 零散
  - tesseract-ocr提供的样本库主要是印刷字体，也就是对于手写字体识别率其实很有限。
* 总结
  以上提到的软件个人只是使用了部分，具体是否适合像Lucene只是简单看了一下文档而已。是否有基于Lucene。
  精度问题，如果只是简单拼凑这些软件的话，精度可能高不到哪里去。需要针对远程桌面这个功能进行特殊的优化。
  实际上如果只是达到目前多数堡垒机的程度的话，其实选用的方案opencv+tesseract-ocr即可（其实OpenCV都可能没必要，还有更加简单的库）。如果大家对软件架构比较感兴趣的话比较推荐《clean Architecture》。
* 问题
  1) 要不要处理RDP协议不传输的那一部分文字，以及VNC的那一部分文字
  2) 要不要处理特定应用的涉及的字体
  3) 文字提取
  4) 要不要文字检索
* 参考
  - [[https://baike.baidu.com/item/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/1140318?fr=aladdin][全文索引介绍]]
  - 《开发数据密集型应用》
  - [[http://2014.jsconf.cn/slides/herman-taobaoweb/#/55][淘宝前后端分离实践]]
  - Lucene中文分词在电子档案全文检索中的应用研究
  - [[https://zh.wikipedia.org/wiki/%E5%85%89%E5%AD%A6%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB][光学字符识别 wiki]]
