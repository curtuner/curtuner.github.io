#+TITLE: 文字识别探索
#+DATE: 2018-05-08
#+LAYOUT: post
#+TAGS: OCR
#+CATEGORIES: OCR

* 前言
  目前Guacamole的图形审计功能只能做到基础的回放，以及根据会话的信息进行简单检索。[fn:1:其实也没有显式支持，不过很大程度只是需要调整UI而已的。]。跟字符协议不同，图形协议传输数据的基本单位是桌面图片（实际上不是，方便起见先这么理解）。图片以及由图片组成的视频（笼统来说）合适人工处理，不适合通过编程进行自动化的处理。现代涉及UI的程序往往倾向于将业务逻辑和UI区分开，也是这个原因。不过如果审计只包含现有的功能，可以进行操作就很少了，尤其是面对大量历史数据的情况下。目前多数堡垒机都是利用了RDP协议的特性[fn:1:需要注意的是当前大多是利用了RDP的特性，所以其他图形协议（如VNC），可能不大适用。]来获取了更多可处理的数据，利用这个数据，带来的提升主要是两个方面：
  - 对多份历史文件检索的能力。
  - 审计单个历史文件的功能。

  所以接下来只讲比较关键的三点：
  1) 如何从图像中提取额外的数据。
  2) 如何通过增加的数据提升历史文件检索功能。
  3) 如何利用额外的数据提升对历史文件分析精度。
* 从历史文件中提取数据
  可供计算机处理的数据是审计功能的基础，其数据量决定了审计功能的上限。目前，我们拥有的数据是Guacamole协议指令。视频文件中目前算是被提取出来的数据只有鼠标位置数据[fn:2:Guacamole直到最近的开发版本才加入的支持。]。
** 面对的问题是什么？
   目标很明显，就是从视频中提取数据，这类任务属于计算机视觉领域的问题。计算机视觉技术就是利用了摄像机以及电脑替代人眼使得计算机拥有人类的双眼所具有的分割、分类、识别、跟踪、判别决策等功能。
   说白了如果能很好地解决这个问题，哪怕只针对RDP，其价值本身就超过了堡垒机这个产品。
** OCR
   OCR（optical character recognition，光学字符识别），是指电子设备（例如扫描仪或数码相机）检查纸上打印的字符，通过检测暗、亮的模式确定其形状，然后用字符识别方法将形状翻译成计算机字符的过程。
  [[./文字识别探索/ocr-to-word.png]]
  
   OCR是一个多学科交叉领域，涉及到计算机视觉（图像处理）、模式识别、机器学习和神经网络等方面知识，属于一个很复杂的领域。一般OCR主要分成了两步：
   1) 文字提取
   2) 文字识别

   其中文字提取的繁杂度远远高于文字识别[fn:1:深度就不一定了，两个属于不同领域。]。
   
   由于RDP已经帮我们提取了一部分文字，这部分文字位图相当于已经完成了文字提取后的位图数据，这部分数据可以比较高效地被文字识别软件识别，
   多数实现了文字审计的堡垒机厂家都避开了文字提取的部分，或者只进行简单的处理。这样就导致了没有办法进行高质量全文搜索的。如果使用这一部分数据
    实际上RDP已经帮我们提取了一部分文字，只要在guacd的RDP模块中截取这一部分数据就可以用于识别了，除此之外还有一部分文字由于不是由Window进行渲染所以只能以图片的形式传输，这里的文字提取主要就是指的这种情况。多数堡垒机的OCR功能都没有处理这一部分数据。也就是说并没有进行文字提取。
*** 文字识别范围的选择
    对于RDP的文字识别，主要涉及两个范围：
    1) 通过RDP的传输文字
    2) 除此之外图像中的文字

    #+BEGIN_SRC plantuml :file 文字识别探索/cover.png
      @startuml
      title 图像中所有文字数据
      node 不直接通过RDP传输的文字数据 {
              node 通过RDP传输的文字数据           
      }
      @enduml
    #+END_SRC

    #+RESULTS:
    [[file:文字识别探索/cover.png]]

   
    
    只识别通过RDP传输的字体和识别整幅图像的字体这两种选择带来的难度差异巨大，这也是为什么几乎没有堡垒机识别整幅图像的文字。因为作出这个选择的代价十分巨大，而且能带来的收益只是全文检索效果的上升。就目前看来哪怕是全文检索的需求都不算很大。
    一旦选择了只识别通过RDP传输文字这一个方向，OCR涉及到的大量技术点就没什么意义了。繁杂的文字提取没有了，加上通过RDP传输的字体本身就是一种字体的位图形式，识别率可以轻松达到很高的程度。原本想介绍一下这个领域的知识。但突然发现其实没有多大意义了。
*** Google Tesseract OCR引擎
    Tesseract的OCR引擎最早于1985年由HP实验室开始研发，1995年该引擎已经成为OCR业内最准确的三款识别引擎之一。Tesseract目前已作为开源项目发布在Google Project。
    目前Tesseract-ocr提供了Python API和C API。直接使用Tesseract-ocr的话两者的接口都不难使用。在机器学习和神经网络加入这个领域之后，今天看来这个软件已经没有那么先进了。但是如果仅仅针对图形审计功能，那么Tesseract-OCR刚刚好够用。说白了，如果只是识别通过RDP传输的文字，OCR部分就没有什么好讲了。相比之下理解一下它的难度所在比较实在。
* 提升文件检索功能
  接下来讨论一下在提取了文字成为字符之后，需要进行的处理。相比图片，字符数据更方便检索。
** Guacamole历史文件格式介绍
   Guacamole历史数据记录了在一个会话的整个交互过程中浏览器获取的所有数据。
   Guacamole使用Guacamole协议来完成桌面的更新，原理上把这个文件只是把Guacamole服务器和客户端的通信过程记录下来而已。就回放这个功能来说，字符和图形的情况都差不多，要不就是复用客户端解析协议的代码来回放，要不就是转化成特定播放器格式再播放。
*** 基本逻辑
    首先，要关注的问题是任意两帧之间的关系两
*** 当前可以用于实现的功能
    关于审计功能，就处理的对象来说可以分成两类：
    - 针对单个历史记录的审计
    - 针对所有历史记录的审计

    两者的关系是，后者往往为前者服务。比如根据特定条件索引到某一份历史记录，最终往往也是为了播放单个历史文件。
    针对单个历史记录的审计，就需求来说，其实很多都是靠近用户界面的需求，类似有效帧播放的需求，只是控制JavaScript。
    Guacamole解析协议的代码是用JavaScript实现的
    就审计的需求而已，审计的需求来说
*** 前端的工作
    如果复用Guacamole的JS代码，前端的任务会比较重，
** 中文分词
   其实分词的问题和审计遇到的问题类似，什么是最小的语义单元？英语中是单词，而中文中是词语，可惜中文中各个词语没有明确的分隔，英文则有明显的间隔。
   分词是中文检索才有的问题，当然其实可以不去做，毕竟通过RDP传输的文字很大一部分已经分好了，考虑到复杂的功能容易出问题，中文分词的价值也进一步降低了。不过情况类似，在某个点存在难度的巨大攀升。
** 检索需求介绍
   说到检索，最简单的方式当然是把数据集合放到内存中遍历一遍，如果发现消耗的时间或者内存不可接受，就可以考虑使用数据库或者其他的某些检索库。一般数据库重点在于解决后者：内存不足问题。
   历史记录检索功能根据范围主要分成三类：
   1) 单个历史记录的检索
   2) 小数量级的多个历史记录的检索
   3) 大数量级的多个历史记录的检索
   
   单个历史记录的检索是最简单的，由于数据量不大，可以采用直接放到内存中遍历一遍的方式，推荐直接在前端完成。如果是查询某个用户在某段时间内的操作历史这一类的小数量级的检索，也可以直接由前端在获取所有数据文件之后遍历检索，开销也可以接受。最大的难点还是在于大数量级的多个历史记录的检索，这个涉及 *全文检索* 领域。
   应用场景
** 全文搜索
   全文搜索是一种数据模型，常常被用在数据库中。支持全文检索模型的软件包括PostgreSQL、MySQL、MongoDB、levelDB这类比较常用的数据库。之所以可以和各种数据库结合，主要原因是这个数据模型本身比较独立，不会和其他数据模型发生冲突。
   全文检索的主要用于高效查询关键字，一旦开了索引，那么就需要在插入新数据的时候维护索引数据结构，插入的开销会随之增大。
*** 检索的基本原理
*** 全文检索和键值检索
    关系数据库默认情况下提供了基础的键值检索功能，根据键可以高效地找到相应的记录，根据键可以查找。
*** Apache Lucene
    Lucene是Elasticsearch和Solr使用的一种全文搜索的索引引擎。它一个完成度很高的软件，在全文检索的领域也是比较出名的软件。当然它是一个框架，不算一个应用软件，要测试其效果可以尝试一下基于它的两个比较出名的软件是：
    1) DocFetcher
    2) Apache solr
    3) Nutch
    
    通过简单定制和优化可以满足上亿级别的检索，同时也支持分布式。之所以需要分布式，主要是全文检索本身是一个开销比较大的功能，使用关系数据库的全文检索功能的时候也要小心对数据库性能造成影响。
    由于Lucene是使用Java编写的软件，所以基于Lucene的项目大多也是Java项目。当然，Python可以通过使用PyLucene来使用Lucene。

*** 针对Guacamole历史文件的搜索引擎设计
    很多检索工具都是基于Lucene进行索引的根据具体
*** Guacamole
* 针对特定模式的处理
  首先，我们知道通过图形界面（GUI）是无法完全获知程序内部逻辑的，这个结论决定图形审计的上限。所以要为图形审计添加功能，就只能 *从能够获取的数据中不断挖掘出特定的“模式”* 。各家堡垒机做的事情无非就是如此，区别只在于挖掘到或者设计的“模式”多少的问题。
** 文字审计
  例如，行云管家提取出了通过RDP传输的文字之后，为此设计的“模式”叫做指令，指令被分成以下四种：
   - 窗口
   - 菜单
   - CMD
   - 其他
   以上。。。当然这种区分似乎有点超前了，可能是先设计了“模式”，再来挖掘“模式”造成，也可能是只注意到某些特例，并为这些特例设计的“模式”。适用范围有限。
** 键盘审计
   这里先用键盘审计举例：
   各家键盘审计价值其实都没有那么大，键盘的处理如果小到单个按键这个粒度（OEM堡垒机），几乎不具备可用性，就像没人看英文会一个个字母看一样，至少要到单词这个粒度。当然现实没那么绝望，即使是单个按键的层面也不是不能找到”模式“，比如PrintScreen键，单个按键就足以表达”打印屏幕“这个语义了。
** 按键“模式”
   处理用户按键信息的情况也类似，由于本身信息不足，想进一步也是挖掘“模式”。单独处理按键信息其实很局限，路很快就走死了（毕竟就那点信息，类似OEM干脆把所有按键信息列出来）。出路大概就是和文字信息结合起来进行“模式“挖掘。
** 高度特化的“模式”
   特化指的是很大一部分模式的适用范围很小。百分百正确的能表现系统状态的“模式”很少，如果局限在这类模式上能做就的很少。如果硬是要做出一定效果，那么需要接受这些限制：
   - 平台受限
   - UI受限
   - 适用范围有限
   - 不保证完全正确
* 相关需求的分析
** 目前支持图形的产品有
  需求上比较大的问题是对于“指令”的概念比较模糊。行云上的指令其实是直接通过RDP传输的文字块，跟键盘无关，可以有意义可可以没意义。称为指令可能不是很合适，个人感觉可能是指令审计还属于设想，离完成还有很大距离。指令记录，
* 总结
  目前看来，为了提升图形审计效果，大体上就是两个方向：
  1) 增强从图像中提取的数据的能力（不单包括文字）
  2) 不断从获取的数据中发现更多”模式“
  
  历史记录的检索效果则取决于能第一个方向走多远。数据量越大，检索的价值也越大。检索性能优化的空间则非常有限，全文检索算是非常成熟的技术了。
  此外，进一步提升图形审计的效果容易遇到这种情况：难度大而带来的收益有限。所以多数堡垒机对图形审计功能的开发其实要不都卡在差不多的地方，要不就只是有个样子。
  总之，并不是不能做，也不是做不好，问题就是技术积累而已
  最后，个人理解，由于能处理的数据量的限制，目前额外做的事情更可能只是中看不中用的处境，对于真正对这类功能有需求的用户来说，一般是难以满足的。如果想更进一步，不是不能做，只是最终能做到的效果以及工作量不好说。
* 零散
  - 最小改动原则
  - 图像改动原则
  - 试试播放的时候并没有开ocr，似乎是为了
* 参考
  - 《设计及数据密集型应用》
  - [[http://guacamole.apache.org/doc/gug/protocol-reference.html#client-sync-instruction][Guacamole protocol reference]]
  - [[https://www.jiqizhixin.com/articles/2017-11-26-2][计算机视觉这一年：这是最全的一份CV技术报告]]
  - 
